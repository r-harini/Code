set.seed(123)
train_samples <- data$V1 %>%
createDataPartition(p=0.8,list=FALSE)
train <- data[train_samples,]
test <- data[-train_samples,]
model1=lm(V1~.,data=train)
summary(model1)
summary(model1)
pred=model1%>%
predict(test)
pred
confint(model1)
RMSE(pred,test$V1)
R2(pred,test$V1)
vif(model1)
model2=lm(V6~.-V2, data=train)
pred2=model2%>%
predict(test)
RMSE(pred,test$V1)
R2(pred,test$V1)
data=biopsy
str(data)
data=data%>%mutate(V6=replace(V6, is.na(V6), mean(V6, na.rm = TRUE)))
data=data[,2:11] #Dropped the ID column
View(data)
set.seed(123)
train_samples <- data$V1 %>%
createDataPartition(p=0.8,list=FALSE)
train <- data[train_samples,]
test <- data[-train_samples,]
model1=lm(V1~.,data=train)
summary(model1)
confint(model1)
RMSE(pred,test$V1)
R2(pred,test$V1)
vif(model1)
model2=lm(V6~.-V2, data=train)
pred2=model2%>%
predict(test)
RMSE(pred2,test$V1)
R2(pred2,test$V1)
model2=lm(V1~.-V2, data=train)
pred2=model2%>%
predict(test)
RMSE(pred2,test$V1)
R2(pred2,test$V1)
model3=lm(V1~.-V2,-V3,data=train)
pred3=model3%>%
predict(test)
RMSE(pred3,test$V1)
R2(pred3, test$v1)
RMSE(pred3,test$V1)
R2(pred3, test$v1)
model3=lm(V1~.-V2-V3,data=train)
pred3=model3%>%
predict(test)
RMSE(pred3,test$V1)
R2(pred3, test$v1)
pred3
RMSE(pred2,test$V1)
R2(pred2,test$V1)
model3=lm(V1~.-V2-V3,data=train)
pred3=model3%>%
predict(test)
RMSE(pred3,test$V1)
R2(pred3, test$v1)
model3=lm(V1~.-V2,-V3,data=train)
pred3=model3%>%
predict(test)
RMSE(pred3,test$V1)
R2(pred3, test$v1)
pred3
R2(pred3, test$v1)
pred2
RMSE(pred3,test$V1)
R2(pred3, test$v1)
pred3
R2(pred3, test$v1)
pred3=model3%>%
predict(test[,2:11])
pred3=model3%>%
predict(test[,2:10])
RMSE(pred3,test$V1)
R2(pred3, test$v1)
pred3=model3%>%
predict(test)
RMSE(pred3,test$V1)
model4=lm(V1~.-V2,-V3, -class, data=train)
model4=lm(V1~.-V2-V3-class, data=train)
#loading Boston housing data in MASS for predicting median house value
data('Boston')
#split the data into training and test data set
set.seed(123)
train_samples <- Boston$medv %>%
createDataPartition(p=0.8,list=FALSE)
#head(train_samples)
train <- Boston[train_samples,]
test <- Boston[-train_samples,]
#Building a regression model
model <- lm(medv~.,data=train)
#Make predictions
pred <- model %>%
predict(test)
vif(model)
set.seed(123)
train_samples <- data$V1 %>%
createDataPartition(p=0.8,list=FALSE)
train <- data[train_samples,]
test <- data[-train_samples,]
model1=lm(V1~.,data=train)
summary(model1)
pred
pred
confint(model1)
RMSE(pred,test$V1)
confint(model1)
RMSE(pred,test$V1)
data=biopsy
str(data)
str(data)
summary(data)
summary(data)
sum(is.na(data$V6))
summary(data)
sum(is.na(data$V6))
data=data%>%mutate(V6=replace(V6, is.na(V6), mean(V6, na.rm = TRUE)))
View(data)
View(data)
data=data[,2:11] #Dropped the ID column
set.seed(123)
train_samples <- data$V1 %>%
createDataPartition(p=0.8,list=FALSE)
test <- data[-train_samples,]
model1=lm(V1~.,data=train)
pred=model1%>%
predict(test)
confint(model1)
RMSE(pred,test$V1)
R2(pred,test$V1)
vif(model1)
model2=lm(V1~.-V2, data=train)
pred2=model2%>%
predict(test)
RMSE(pred2,test$V1)
R2(pred2,test$V1)
model3=lm(V1~.-V2-V3,data=train)
pred3=model3%>%
predict(test)
RMSE(pred3,test$V1)
R2(pred3, test$v1)
model4=lm(V1~.-V2-V3-class, data=train)
pred4=model4%>%
predict(test)
RMSE(pred4,test$V1)
R2(pred4,test$V1)
R2(pred3,test$V1)
model3=lm(V1~.-V2-V3,data=train)
pred3=model3%>%
predict(test)
RMSE(pred3,test$V1)
R2(pred3,test$V1)
model4=lm(V1~.-V2-V3-class, data=train)
pred4=model4%>%
predict(test)
RMSE(pred4,test$V1)
R2(pred4,test$V1)
RMSE(pred3,test$V1)
RMSE(pred2,test$V1)
RMSE(pred4,test$V1)
RMSE(pred,test$V1)
R2(pred3,test$V1)
plot(model3,1)
plot(model3,2)
plot(model3,3)
plot(model3,4)
IQR(data$V5)
IQR(data$V5)
model4=lm(V1~V4*V5, data=train)
pred4=model4%>%
predict(test)
RMSE(pred4,test$V1)
R2(pred4,test$V1)
model5=lm(V1~V4+V5,data=train)
pred5=model5%>%
predict(test)
RMSE(pred5,test$V1)
R2(pred5,test$V1)
library(MASS)
library(tidyverse)
library(caret)
#loading Boston housing data in MASS for predicting median house value
data('Boston')
#split the data into training and test data set
set.seed(123)
train_samples <- Boston$medv %>%
createDataPartition(p=0.8,list=FALSE)
#head(train_samples)
train <- Boston[train_samples,]
test <- Boston[-train_samples,]
#Building a regression model
model <- lm(medv~.,data=train)
#Make predictions
pred <- model %>%
predict(test)
#model performance
RMSE <- RMSE(pred,test$medv)
RMSE
R2 <- R2(pred,test$medv)
R2
#Detecting multicollinearity
library(car)
vif(model)
#Dealing with multicollinearity
#Building a model excluding those variables
model2 <- lm(medv~.-tax,data=train)
pred2 <- model2%>%
predict(test)
data.frame(
RMSE <- RMSE(pred2,test$medv),
R2 <- R2(pred2,test$medv)
)
model3 <- lm(medv~.-rad,-tax,data=train)
pred2 <- model3%>%
predict(test)
data.frame(
RMSE <- RMSE(pred2,test$medv),
R2 <- R2(pred2,test$medv)
)
par(mar=c(2,2,2,2))
par(mfrow=c(2,2))
plot(model)
#-------------------
library(datarium)
data("marketing")
str(marketing)
head(marketing)
#building a linear model
model <- lm(sales~youtube,data=marketing)
model
View(marketing)
View(marketing)
model2 <- lm(log(sales)~youtube,data=marketing)
plot(model,1)
plot(model,2)
plot(model,3)
plot(model,5)
model2 <- lm(log(sales)~youtube,data=marketing)
plot(model2,3)
#building a linear model
model <- lm(sales~youtube,data=marketing)
#confidence interval
confint(model)
library(MASS)   #MASS - Modern Applied Statistics with S
#Qualitative data
#compute the frequency distribution of school variable
sch_freq <- table(painters$School)
cbind(sch_freq)
#compute the relative frequency of school variable
rel_sch_frequ <- sch_freq/nrow(painters)
old <- options(digits = 1)
rel_sch_frequ
cbind(rel_sch_frequ)
options(old)
#find the mean composition of painters in school 'C'
c_p <- painters[painters$School=='C',]
mean(c_p$Composition)
options(digits=2)
#find the mean composition of painters in all schools
tapply(painters$Composition, painters$School, mean)
View(c_p)
View(c_p)
rm(list=ls())
library(dplyr)
library(ggplot2)
library(car)
library(caret)
df=read.csv("CreditCard.csv")
str(df)
tai(df,10)
tail(df,10)
View(df)
View(df)
summary(df$income)
summary(df$income, df$share)
summary(df$share)
summary(df$expenditure)
df$card=as.factor(df$card)
str(df)
df$owner=as.factor(df$owner)
str(df)
df=read.csv("CreditCard.csv", stringsAsFactors = TRUE)
str(df)
tail(df,10)
d=df%>%
filter(owner='no' & card='no')
d=df%>%
filter(owner=='no' & card=='no')
mean(d$income)
which.max(d$share)
max(d$share)
min(d$expenditure)
s=sample(df$income, size=15)
s
boxplot(s)
boxplot(s, main="Samples of Income")
sd(df$income)
newdf=df%>%
mutate(case_when(income<=2.5~"low",
income>=2.5 & income<=4~"medium",
income>4~"high"))
View(newdf)
View(newdf)
newdf=df%>%
mutate(income_cat=case_when(income<=2.5~"low",
income>=2.5 & income<=4~"medium",
income>4~"high"))
View(newdf)
View(newdf)
colnames(newdf)
head(newdf$income_cat,10)
freq=table(df$owner)
freq
rel_freq=freq/nrows(df)
rel_freq=freq/nrow(df)
rel_freq
ggplot(df, aes(x=owner, fill=owner))+geom_bar()
ggplot(df, aes(x=owner, fill=owner))+geom_bar()+ggtitle("Frequency distribution of the owners")+xlab("Owning the house: Yes or No")+ylab("Frequency")
cor(df$income, df$expenditure)
data=df[,2:13]
View(data)
View(data)
View(data)
View(data)
View(df)
View(df)
set.seed(123)
train_samples <- data$expenditure %>%
createDataPartition(p=0.8,list=FALSE)
train <- data[train_samples,]
test <- data[-train_samples,]
model1=lm(expenditure~.,data=train)
summary(model1)
pred=model1%>%
predict(test)
confint(model1)
vif(model1)
model2=lm(expenditure~.-selfempyes, data=train)
model2=lm(expenditure~.-selfemp, data=train)
summary(model2)
model2=lm(expenditure~.-selfemp,-owner, data=train)
model2=lm(expenditure~.-selfemp, data=train)
summary(model2)
model3=lm(expenditure~
income+share+months+active, data=train)
summary(model3)
RMSE(pred,test$expenditure)
R2(pred,test$expenditure)
pred2=model1%>%
predict(test)
RMSE(pred2, test$expenditure)
R2(pred2,test$expenditure)
model3=lm(expenditure~
income*share*months+*active, data=train)
model3=lm(expenditure~
income*share*months*active, data=train)
summary(model3)
pred2=model2%>%
predict(test)
RMSE(pred2, test$expenditure)
R2(pred2,test$expenditure)
model2=lm(expenditure~.-selfemp,-owner, data=train)
model2=lm(expenditure~.-selfemp-owner, data=train)
summary(model2)
model2=lm(expenditure~.-selfemp-card-majorcards, data=train)
summary(model2)
pred2=model2%>%
predict(test)
RMSE(pred2, test$expenditure)
R2(pred2,test$expenditure)
model3=lm(expenditure~
age*dependents,data=train)
summary(model3)
model3=lm(expenditure~
age*dependents+months,data=train)
summary(model3)
model3=lm(expenditure~
age+dependents+months,data=train)
summary(model3)
model3=lm(expenditure~
age+dependents+months+active,data=train)
summary(model3)
pred3=model3%>%
predict(test)
RMSE(pred3, test$expenditure)
R2(pred3, test$expenditure)
model4=lm(expenditure~log(share)*age*income*dependents,data=train)
summary(model4)
pred4=model4%>%
predict(test)
RMSE(pred4,test$expenditure)
R2(pred4,test$expenditure)
pred5=model5%>%
predict(test)
model5=lm(expenditure~
income*share*months*active, data=train)
summary(model5)
pred5=model5%>%
predict(test)
RMSE(pred5,test$expenditure)
R2(pred5,test$expenditure)
plot(model5,1)
plot(model5,1)
plot(model5,2)
plot(model5,3)
plot(model5,4)
table(newdf$income_cat,newdf$card)
t=newdf%>%
filter(card=="no")
table(t$income_cat)
which.max(table(t$income_cat))
which.max(table(t$income_cat))[1]
which.max(table(t$income_cat))[[1]]
max(table(t$income_cat))
which.max(table(t$income_cat))[1]
max(table(t$income_cat))
View(newdf)
View(newdf)
newdf%>%
filter(income_cat=="low" & owner=="yes" & selfemp=="yes" & card=="yest")
newdf%>%
filter(income_cat=="low" & owner=="yes" & selfemp=="yes" & card=="yes")
median(d$share)
s=sample(df$income, size=15)
boxplot(s, main="Samples of Income")
View(newdf)
View(newdf)
model6=lm(expenditure~
card*income*share*selfemp*majorcards,data=train)
summary(model6)
pred6=model6%>%
predict(test)
pred6=model6%>%
predict(test)
RMSE(pred6,test$expenditure)
R2(pred6,test$expenditure)
model6=lm(expenditure~
card*income*selfemp*majorcards,data=train)
summary(model6)
pred6=model6%>%
predict(test)
RMSE(pred6,test$expenditure)
R2(pred6,test$expenditure)
rm(list=ls())
library(dplyr)
library(ggplot2)
library(car)
library(car)
library(ggpubr)
data=read.csv("heart.csv")
colnames(data)[1]="age"
colnames(data)
#Converting the required columns to factors
str(data)
#Converting the required columns to factors
str(data)
data=data%>%
mutate(sex=replace(sex, sex==1, "Male"))
data=data%>%
mutate(sex=replace(sex, sex==1, "Male"))
data=data%>%
mutate(sex=replace(sex, sex==0, "Female"))
data=data%>%
mutate(sex=replace(sex, sex==0, "Female"))
data=data%>%
mutate(target=replace(target, target==1, "Yes"))
data=data%>%
mutate(sex=replace(sex, sex==1, "Male"))
data=data%>%
mutate(sex=replace(sex, sex==0, "Female"))
data=data%>%
mutate(target=replace(target, target==1, "Yes"))
data=data%>%
mutate(target=replace(target, target==0, "No"))
data=data%>%
mutate(sex=replace(sex, sex==1, "Male"))
data=data%>%
mutate(sex=replace(sex, sex==0, "Female"))
data=data%>%
mutate(target=replace(target, target==1, "Yes"))
data=data%>%
mutate(target=replace(target, target==0, "No"))
data$sex=as.factor(data$sex)
data$slope=as.character(data$slope)
data$slope=as.factor(data$slope)
str(data)
var.test(chol~slope, data=data, alternative="two.sided")
var.test(chol~sex, data=data, alternative="two.sided")
res=var.test(chol~slope,data)
res=var.test(chol~sex, data=data, alternative="two.sided")
res
res.ftest$estimate
res$estimate
res$p.value
data=read.csv("Train.csv")
setwd("C:/Code/RStudio/AI")
data=read.csv("Train.csv")
str(data)
data$ClassId=as.factor(data$ClassId)
res=aov(Height~ClassId,data)
summary.aov(res)
library(car)
leveneTest(Height~ClassId,data)
