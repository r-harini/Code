---
title: "LabEx8-Regression Analysis"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---
### Reg. No: 18BCE1010

### Name: R. Harini

## Setup


### Load packages if any using library(packagename)
```{r}
rm(list=ls())
library(tidyverse)
library(caret)
library(ggplot2)
library(car)
```


### Load data
```{r}
data=read.csv("Real_Estate.csv")

```

### Do the regression analysis on the chosen data set and provide your inference
* * *
#### Visualization
```{r}
ggplot(data, aes(x=house.age ,y=Price))+geom_point()
ggplot(data, aes(x=house.age ,y=Price))+geom_point()+geom_smooth()
ggplot(data, aes(x=house.age ,y=Price))+geom_point()+geom_smooth(method="lm", se=FALSE)

```

#### Finding the correlation
```{r}
cor(data$house.age, data$Price)
```
#### Building a model using only House Age variable
```{r}
model1=lm(Price~house.age, data = data)
model1
```

#### Model 1 Summary
```{r}
summary(model1)
```

#### Confidence interval of Model 1
```{r}
confint(model1)
```

#### RSE of Model 1
```{r}
sigma(model1)*100/mean(data$Price)
```
#### Correlation between all variables 
```{r}
cor(data$Price, data$distance.to.the.nearest.MRT.station)
```

#### Building a model using Distance variable
```{r}
model2=lm(Price~distance.to.the.nearest.MRT.station,data)
model2
```

#### Model 2 summary
```{r}
summary(model2)
```

#### Confidence interval for Model 2
```{r}
confint(model2)
```

#### RSE of Model 2
```{r}
sigma(model2)*100/mean(data$Price)

```

### Your Inference for regression analysis
* * *
```{r}
# Based on Model1 and Model2 scores, we can say Model 2 is better as it has a higher f-statistic and t-statistic value than Model 1. 
#Model 2 also has a lower RSE than Model 1 which indicates it as being a better model.
```


* * *


* * *

### Do the regression diagnostics on the chosen data set 
* * *
#### Splitting the data into training and test set
```{r}
set.seed(123)
train_samples=data$Price%>%
  createDataPartition(p=0.8,list=FALSE)
train <- data[train_samples,]
test <- data[-train_samples,]
```

#### Building a regression model
```{r}
model=lm(Price~., data=data)
```

#### Making predictions
```{r}
pred <- model %>%
  predict(test)
```

#### Computing RMSE
```{r}
RMSE <- RMSE(pred,test$Price)
RMSE
```
#### Computing R2
```{r}
R2 <- R2(pred,test$Price)
R2
```
#### Detecting Multicollinearity
```{r}
vif(model)
```

```{r}
plot(model)
```

* * *

### Provide your inference of the regression diagnostics  
```{r}
# Based on the plots,we can see that the the points follow a straight line which means the model fit is good. 
#Also the RMSE value is quite low. With R2 value as 0.6, we can say that it can explain 60% of the data properly. 
#Since the VIF values dont exceed 5, we can infer that the variance of the regression coefficient is not inflated due to multicollinearity.
```


* * *


* * *



